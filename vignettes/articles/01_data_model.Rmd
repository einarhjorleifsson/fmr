---
title: "The data model"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = "#>"
)
```

```{r}
library(fmr)
library(tidyverse)
```

## Preamble

This document is just to explore the FM data model, done to prevent any misunderstanding when setting up the downstream code. In addition it deals with some issues and questions that arise related to the data-entry of catch-sample data.

The FM API on is made up from three tables ([The Data Structured Explained](https://fimsehf.atlassian.net/wiki/x/zgC7ww)).

1. Survey table - distinguished by survey_id
2. Trip table - distinguished by trip_id (survey_item_id)
3. Catch table - distinguished by .id (survey_item_dtl_id)

The conceptual design (if one is considering catch-sampling on landing sites) is depicted as:

```{r, echo = FALSE, eval = FALSE}
#| fig.cap: "Source: Fisheries Technologies."
knitr::include_graphics(here::here("vignettes/articles/data_model1.png"))
```

The FM 3 table framework is not specific for sampling from landings, but lets here think about these three tables in that context.

1. Sampling site table (survey table): For catch-sampling from landings data one could imagine that each record represents information about the sampling from a particular sampling site on a particular sampling date (this though not the necessary case as discussed below).
2. Trip table (surveyitem table): In case of catch sampling from landings this table should contain all information related to a single fishing trip except details of catch.
3. Catch table (surveyitem detail table): In case of catch sampling from landings this table will contain the detailed information about catch by species.

## The connection



```{r, eval = FALSE}
key <- "your_FM_API_key"
```

```{r, echo = FALSE}
key <- Sys.getenv("fm_key")
```

## The three survey tables

Let's start by loading in tables needed, if only because we need information from the downstream tables to make sense of the upstream tables:

```{r}
survey <- fm_survey(key, trim = FALSE)
trip <- fm_trip(key)
catch <- fm_catch(key)
```


### The landing site-date table (Survey table)

```{r}
survey |> glimpse()
```

Each survey is identified by a unique value stored as *survey_id*. Intuitively one expects that each survey id constitutes a unique number for each landing site (*site*) by each sampling day (*date*). This is however not necessarily the case, as demonstrated below.

#### What does a single survey_id  represent?

Let's take a look at one month of data from one site:

```{r}
d <- 
  survey |> 
  # look at one month
  filter(year(date) == 2024, month(date) == 1,
         site == "Basseterre East") |>
  arrange(date) |> 
  group_by(site, date) |> 
  summarise(n = n_distinct(survey_id),
            .groups = "drop")
d |> 
  knitr::kable(caption = "Number of surveys per date")
```

Visually we have:

```{r}
d |> 
  mutate(survey = TRUE) |> 
  fm_grid_calendar() |> 
  mutate(weekend = ifelse(.wday %in% c("Sa", "Su"),
                          TRUE,
                          FALSE),
         survey = replace_na(survey, FALSE)) |> 
  ggplot(aes(.wday, .week)) +
  theme_bw() +
  geom_tile(aes(fill = survey),
            colour = "black") +
  facet_wrap(~ site) +
  geom_text(aes(label = .day, colour = weekend)) +
  geom_text(aes(label = n), nudge_x = 0.2, nudge_y = -0.2,
            size = 3, colour = "blue") +
  scale_fill_manual(values=c("grey80", "pink")) +
  scale_colour_manual(values = c("black", "red")) +
  scale_y_reverse(NULL, NULL) +
  labs(x = NULL,
       title = "January 2024",
       caption = "colour: reported sampling day") +
  coord_equal() +
  theme(legend.position = "none",
        legend.title=element_blank(), 
        panel.grid=element_blank(), 
        panel.border=element_blank(), 
        axis.ticks=element_blank(), 
        strip.background=element_blank(), 
        #legend.position="top", 
        legend.justification="right", 
        legend.direction="horizontal", 
        legend.key.size=unit(0.3, "cm"), 
        legend.spacing.x=unit(0.2, "cm"))
```

Here the pink shade marks days that surveys were conducted and the blue colour represents the number of unique reported surveys. There are two points to observe here:

* Having a survey date on a weekend is unexpected because observers do not work on those days.
* The number of surveys per day are in many cases more than 1

Let's look first at the weeend data:

```{r}
d <- 
  survey |> 
  # look at one month
  filter(year(date) == 2024, month(date) == 1,
         site == "Basseterre East") |> 
  mutate(wday = wday(date, label = TRUE, locale = "en_GB.utf8")) |> 
  filter(wday %in% c("Sat", "Sun")) |> 
  count(survey_id, date, wday) |> 
  arrange(date)
d
```

Here we see that we have:

* 3 survey weekdays



Ad hoc question:


```{r}
survey |> 
  select(survey_id, date, .cn, .ct) |> 
  filter(year(date) == 2024) |> 
  inner_join(trip |> select(vid, survey_id, trip_id, dep_time, arr_time)) |> 
  inner_join(catch |> select(trip_id, type = measurement_type) |> distinct()) |> 
  select(vid, date, type, dep_time, arr_time, everything()) |> 
  arrange(vid, date, type) |> 
  group_by(vid, date, type) |> 
  mutate(n = n(), .after = type) |> 
  ungroup() |> 
  filter(n > 1) |> 
  knitr::kable()
```



One could implement a unique id within the R-function, named e.g. *.sid*. We can test that via:

```{r}
survey <- 
  survey |> 
  # just so we can get the original order back
  mutate(.rowid = 1:n()) |> 
  arrange(site, date, T1) |> 
  mutate(.sid = dplyr::consecutive_id(site, date)) |> 
  arrange(.rowid) |> 
  select(-.rowid)
survey |> 
  summarise(n_sid = n_distinct(.sid),
            n_surveyid = n_distinct(survey_id),
            .groups = "drop")
```

One would use this table e.g. to get an overview of the reported sampled dates:

```{r, fig.width = 9, fig.height = 9}
fm_survey(key, trim = FALSE) %>% 
  filter(year(date) == 2024,
         month(date) == 1) |> 
  select(site, date) |> 
  distinct() |> 
  mutate(survey = TRUE) |> 
  fm_grid_calendar() |> 
  mutate(weekend = ifelse(.wday %in% c("Sa", "Su"),
                          TRUE,
                          FALSE)) %>% 
  #filter(site == "Charlestown") |> 
  ggplot(aes(.wday, .week)) +
  theme_bw() +
  geom_tile(aes(fill = survey)) +
  facet_wrap(~ site) +
  geom_text(aes(label = .day, colour = weekend)) +
  scale_fill_manual(values=c("grey80", "pink")) +
  scale_colour_manual(values = c("black", "red")) +
  scale_y_reverse(NULL, NULL) +
  labs(x = NULL,
       title = "January 2024",
       caption = "colour: reported sampling day") +
  coord_equal() +
  theme(legend.position = "none",
        legend.title=element_blank(), 
        panel.grid=element_blank(), 
        panel.border=element_blank(), 
        axis.ticks=element_blank(), 
        strip.background=element_blank(), 
        #legend.position="top", 
        legend.justification="right", 
        legend.direction="horizontal", 
        legend.key.size=unit(0.3, "cm"), 
        legend.spacing.x=unit(0.2, "cm"))
```

#### Some issues

Do not expect that one can create a survey without a survey date:

```{r}
survey |> 
  filter(is.na(date)) |> 
  select(survey_id, site, date, status, T1, T2, n_boats = total_boats, comment,
         collector,
         .cn:.ut) |> 
  arrange(survey_id) |> 
  glimpse()
```

### The surveyitem table

This is effectively the trip table.

```
QC: Expect only one trip per vessel per day
```

```{r}
trip |> 
  mutate(d1 = as_date(dep_time),
         d2 = as_date(arr_time)) |> 
  count(vid, d1) |> 
  count(n) |> 
  rename('Trips per day' = n, 
         'Number of records' = nn) |> 
  knitr::kable(caption = "Number of trips by vessels per day")
```

```{r}
trip |> 
  mutate(d1 = as_date(dep_time))
```


### The surveyitemdtl table

```{r}
catch <- fmr::fm_catch(key)
catch |> glimpse()
```


### The catch table (Survey item table)

pending further coding ...


## The wide tables

Combining these three data tables into a single wide-table is very common delivery approach when the downstream analysis is based on some kind of a spreadsheet software. The problem here though is that each measurements in the trip table gets repeated by the number of species recorded in the catch table and then the records associated with the sampling site get repeated by the number of trips. E.g. if on one sampling site within one day one samples 10 trips and for each of those 10 trips we measure 5 species we have 50 (10 trips x 5 species) repeated records of the variables associated with the sampling site table.

Wide-tables where one has repeated records of the same measure create a bit of a problem in statistical analysis, in particular when there are a lot of variables (columns) in such a wide-table. In order that any code generated is delivering what is intended the person using the wide-table has to have a full knowledge of the data-model in the first place. Which defies hence the logic of providing a wide table.

Of course on can access the wide tables provided by FM via {fmr} as shown below. Although wide tables are often used when using spreadsheet software, it is not recommended to use them for downstream analysis in R:

### landing F
```{r}
fm_landingF(key) |> glimpse()
```

### landingV
```{r}
fm_landingV(key) |> glimpse()
```

## What is in common with all fisheries and fisheries science data-collection

### Top-down thinking

#### H1 - survey

1. We go on a **trip**:
  * This could be a trip to a landing site
  * This could be a scientific survey ("a cruise"/"lei√∞angur")
  * This could be a commercial fishing trip
  
```
We normally would record at minimum time and space at different degree of resolution
  time: quarter, month, date, time, start, end, ...
  space: fao area, eez, area, statistical rectangle, geograhical name, lon, lat, ...

If a landing survey, the start and end space would normally be the same.

If a scientific cruise or a fishing trip, the start/end space elements may differ. Therein, we may actually have a visit to port, with or without any landing event.
```

#### H2 - item

2. During a trip we take some **itemized** samples
  * If a landing "survey", we sample **boats** (read: trips).
    * The landing survey could be a subsample of trips or a full census (read: all trips).
      * If subsample of trips, we would still need info on the total effort (in a day-boat system, some estimated of the number of boats that go out. I.e. anything that allows us to raise the sample to a total estimate).
      * If full census we have the total effort (at least in terms of the number of trips).
      * Here the sampling space is the same (a landing site) but we may still get more detailed information on time and space. If so that recorded at the next node downstream (see below).
  * If a scientific survey we take samples at a **station** (space and time)
  * If a commerical fishing trip we take "samples" at a **station"* (space and time - think captain logbooks)
  
```
Whatever the case at level H2, we would at minimum record time and space

For a landing survey we would record the start and end time of the trip

For logbooks we would record time and space of the tow (whatever resolution)

For a scientific survey we would record time and space of any action on "a station"
```
  
#### H3 - item details

We may do different things at "a station":

* Measure of fish weight/number by species (or species group)
  * If landings (sample or census): trip weights/numbers by species, possibly split to type (whole, gutted, fillets, breadcrumbs, ...), preservation (none, iced, "krapi", frozen, dried, ...) and estimation type (visual, weighted, ...)
  * If commercial logbooks - by time and space of fishing
  * If scientic curse - by time an sace of fishing
    * If a scientific cruise we may actually not record total number or total weight by species. But that number will/should always be derivable 


#### H4 - measurements details





## Think from the bottom up - the base is the station

Most likely a scientific survey is the most "complicated" thing when it comes to data structure/parameters collected Lets first start from thinking about resource survey, like the icelandic gillnet survey.

Station here is considered to be a physical entity associated with time, space and/or potentially other physical parameter.


We may have:

* **Station** parameters that includes things like:
  * t1 &  t2: time start and end time at station
  * lon1, lat1, lon2, lat2: coordinates, start and end
  * z1 & z2: depth, start and end
  * bt1 & bt2: bottom temperature, start and end (rarely both)
  * st1 & st2: surface temperature, start and end (rarely both)
  * additional oceanographic informations (wind, sky, ocean condition, ice, air-pressure, currents, secci depth, ...)

At each station we may deploy different gear (not limited to fishing gear) - each of the gear is identified by a unique key (lets call it sample_id). A separate sample is created for each gear. In the case of e.g. of a gill-net survey where we have multiple mesh sizes, each synis_id constitutes a different mesh size. In the case of a gear selectivity survey, one synis_id may be for the sample collected in the cod-end of the main trawl, while the other synis_id is reserved for the fish that are collected in the retaining bag (i.e. fish that pass though the mesh of the main gear, but retained by the "backend" gear).



